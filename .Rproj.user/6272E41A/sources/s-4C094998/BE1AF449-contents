---
title: "Reading file types"
author: "Riccardo Piani"
date: "26/2/2020"
output:
  html_document:
    number_sections: yes
    theme: cerulean
    toc: yes
  pdf_document:
    toc: yes
subtitle: 'Data Science Specialization > Getting and Cleaning Data > week 1'
---

```{r setup, include=FALSE}
rm(list = ls(all.names = TRUE))
cat("\014")
if(!is.null(dev.list())) dev.off()
gc()
knitr::opts_knit$set(root.dir = "F:/DATA")
knitr::opts_chunk$set(echo = TRUE)
```
<div style="page-break-after: always;"></div>
```{r echo = FALSE}
R.version.string

library(xlsx)
library(XML)
library(httr)
library(jsonlite)
library(data.table)
```


# Downloading Files

```{r}
# Attention: use /, not \
setwd("F:/DATA")
getwd()
setwd("../")
getwd()
setwd("./data")
getwd()

# file.exists --> check directory
if(!file.exists("test")) {
    dir.create("test")
}
# from internet
fileUrl <- "https://data.baltimorecity.gov/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
# curl for https
download.file(fileUrl, destfile = "./test/cameras.csv", method = "curl") 
list.files("./test")

dateDownloaded <- date()
dateDownloaded
```

# Reading Local Files

```{r}
# read.table (not for large dataset)
# important parameters: file, header, sep, row.names, nrows

# error
#cameraData <- read.table("./test/cameras.csv") 
#head(cameraData)

# ok
cameraData <- read.table("./test/cameras.csv", sep = ",", header = TRUE) 
head(cameraData)

# read.csv sets sep = "," and header=TRUE
# if there are quotation marks ' or "", set quote="" --> means no quotes
cameraData <- read.csv("./test/cameras.csv") 

#View(cameraData)
```

# Reading Excel Files 

```{r}
# NOT advised usage of xlsx !!!!

# library(xlsx)
fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.xlsx?accessType=DOWNLOAD"
# curl for https
download.file(fileUrl, destfile = "./test/cameras.xlsx", method = "curl") 
list.files("./test")

dateDownloaded <- date()
dateDownloaded

#cameraData <- read.xlsx("./test/cameras.xlsx", sheetIndex = 1, header = TRUE)
#csp <- read.xlsx("CSP.20200119.xlsx", sheetIndex = 1, header = TRUE)

#View(cameraData)
#View(csp)
# head(csp)
# nrow(csp)

#   Limitando, carica solo quello che serve --> molto più veloce
colIndex <- 2:3
rowIndex <- 1:4
cspSubset <- read.xlsx("CSP.20200119.xlsx", sheetIndex = 1, header = TRUE, colIndex = colIndex, rowIndex = rowIndex)
cspSubset

# read.xlsx2 muche faster, not for subsetting
```

# Reading XML Files

```{r}
# !!!! XML package doesn't work great with redirects (http -> https, your URL starting with http) and with https
# --> library(httr)

# library(XML)
fileUrl <- "http://www.w3schools.com/xml/simple.xml"
doc <- xmlParse(rawToChar(GET(fileUrl)$content))
#doc <- xmlTreeParse(fileUrl, useInternalNodes = TRUE)
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode) # 1° level
doc
class(rootNode[[1]]) # "XMLAbstractNode"
class(rootNode[1]) # "XMLInternalNodeList" "XMLNodeList" 

rootNode[[1]]
rootNode[[1]][[1]]

# xmlSApply
xmlSApply(rootNode, xmlValue)

# XPath ----

# elenco di utti i tag <name>
xpathSApply(rootNode, "//name", xmlValue)
# elenco di utti i tag <price>
xpathSApply(rootNode, "//price", xmlValue)


# htmlParse
fileUrl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
#doc <- htmlTreeParse(fileUrl, useInternal = TRUE)
doc <- htmlParse(rawToChar(GET(fileUrl)$content))
sub <- xpathSApply(doc, "//li[@class = 'sub']", xmlValue)
sub
```

# Reading JSON Files 

```{r}
# JSON: JavaScript Object Notation
# Commom for API (Application Programming Interfaces)

# fromJSON --> trasforma in tabella
jsonData <- fromJSON("https://api.github.com/users/jtleek/repos")
head(jsonData)
names(jsonData)
names(jsonData$owner)
jsonData$owner$login

# transform to JASON
myjson <- toJSON(iris, pretty = TRUE)
cat(myjson) # con-catenate, similar to print

iris2 <- fromJSON(myjson)
head(iris2)

```

# data.table Package 

```{r}
DF <- data.frame(x = rnorm(9), y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))
head(DF, 3)

DT <- data.table(x = rnorm(9), y = rep(c("a", "b", "c"), each = 3), z = rnorm(9))
head(DT, 3)
tables()
#View(DT)

DT[2, ]
DT[DT$y == "a", ]
DT[c(2, 3)] # with only one index it subset the rows  (data frame subsets columns)
DT[, c(2, 3) ]

# column subsetting DIFFERENT FROM DATA FRAME !!!!
DT[, list(mean(x), sum(z))]
DT[, table(y)]
DT[, w:=z^2]    # adding new column
DT
DT2 <- DT
DT[, y:=2]
DT
DT2 #  !!!! also DT2 is changed

DT[, m:= {tmp <- (x+z); log2(tmp + 5)}]
DT
DT[, a:=x>0]
DT
DT[, b:= mean(x+w), by = a]  # --> by  = group by

set.seed(123)

# .N an integer, length 1, containing the number (tipo count)
DT <- data.table(x = sample(letters[1:3], 1E5, TRUE))
nrow(DT)
DT[, .N, by = x]

# keys
DT <- data.table(x = rep(c("a", "b", "c"), each = 100), y = rnorm(300))
DT
setkey(DT, x)
DT['a']

# Joins
DT1 <- data.table(x = c('a', 'a', 'b', 'dt1'), y = 1:4)
DT2 <- data.table(x = c('a', 'b', 'dt2'), z = 5:7)
setkey(DT1, x)
setkey(DT2, x)
merge(DT1, DT2)

# fast reading  --> fread
big_df <- data.frame(x = rnorm(1E6), t = rnorm(1E6))
file <- tempfile()
write.table(big_df, file = file, row.names = FALSE, col.names = TRUE, sep = "\t", quote = FALSE)
system.time(fread(file))
system.time(read.table(file, header = TRUE, sep = "\t"))

```


# Week 1 Quiz

```{r error = TRUE}
# 1 How many properties are worth $1,000,000 or more?  --> 53
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "w01_01.csv", method = "curl") 

dt <- read.csv("w01_01.csv")
str(dt$VAL)
dt1 <- dt[!is.na(dt$VAL), ]
dt1 <- dt1[dt1$VAL==24, ]
nrow(dt1)

# 2 Consider the variable FES in the code book. Which of the "tidy data" principles does this variable violate?
dtFES <- dt$FES
table(dtFES)

# 3 --> 36534720
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile = "data.gov_NGAP.xlsx", method = "curl") 

colIndex <- 7:15
rowIndex <- 18:23
dat <- read.xlsx("data.gov_NGAP.xlsx", sheetIndex = 1, header = TRUE, colIndex = colIndex, rowIndex = rowIndex)
sum(dat$Zip*dat$Ext,na.rm=T)

# 4 --> 127
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlParse(rawToChar(GET(fileUrl)$content))
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode) # 1° level
sum(xpathSApply(rootNode, "//zipcode", xmlValue) == "21231")

# 5

options(digits.secs = 10) 

fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile = "w01_05.csv", method = "curl") 
DT <- fread("w01_05.csv")
class(DT)

delta <- function(f) {
    start.time <- Sys.time()
    eval(f)
    end.time <- Sys.time()
    time.taken <- end.time - start.time
    time.taken
}

delta(rowMeans(DT)[DT$SEX==1]) + delta(rowMeans(DT)[DT$SEX==2])
delta(tapply(DT$pwgtp15, DT$SEX, mean))
delta(sapply(split(DT$pwgtp15, DT$SEX), mean))
delta(mean(DT$pwgtp15, by = DT$SEX)) # NO
delta(DT[, mean(pwgtp15), by = SEX])
delta(mean(DT[DT$SEX==1,]$pwgtp15)) + delta(mean(DT[DT$SEXX==2,]$pwgtp15))


```


